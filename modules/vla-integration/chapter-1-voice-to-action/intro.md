# Chapter 1: Voice-to-Action Overview

This chapter introduces the Vision-Language-Action (VLA) system's voice command processing.  
Students will learn how to capture voice commands, validate them, and interpret user intent for robotic actions.

## Modules in this chapter
- `voice_capture.py` → Capturing audio input
- `voice_processor.py` → Validating and scoring commands
- `whisper_pipeline.py` → Whisper transcription pipeline
- `basic_workflow.py` → Complete voice command workflow
- `whisper_integration.py` → Integration with OpenAI Whisper
- `speech-processing-examples.py` → Educational examples and demos
